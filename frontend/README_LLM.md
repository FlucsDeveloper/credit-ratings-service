# Credit Ratings Service - LLM Configuration

## üìö Documenta√ß√£o Completa

Este sistema suporta **m√∫ltiplos LLM providers** com fallback autom√°tico para regex quando LLM n√£o est√° configurado.

---

## üéØ Quick Start

### **Modo 1: Gr√°tis (Regex-only) - Recomendado para come√ßar**

N√£o configure nenhuma API key. O sistema funcionar√° 100% gr√°tis usando regex.

```bash
# .env.local
# Deixe vazio ou adicione:
LLM_PROVIDER=none
```

**O que funciona:**
- ‚úÖ Empresas no banco de dados (Microsoft, Apple, etc.)
- ‚úÖ P√°ginas bem formatadas das ag√™ncias de rating
- ‚úÖ 100% gr√°tis, sem limites
- ‚ùå P√°ginas mal formatadas (artigos de not√≠cias, PDFs, etc.)

---

### **Modo 2: Produ√ß√£o Institucional (OpenAI GPT-4o-mini)**

Para **produ√ß√£o institucional** (bancos, fundos), use OpenAI para melhor qualidade.

```bash
# .env.local
OPENAI_API_KEY=sk-proj-...sua-chave-aqui...
LLM_PROVIDER=openai
```

**Benef√≠cios:**
- ‚úÖ 95%+ accuracy em extra√ß√£o
- ‚úÖ API est√°vel (99.9% uptime)
- ‚úÖ Suporte empresarial dispon√≠vel
- ‚úÖ ~$14/ano para 1000 queries/dia

**üìñ [Guia completo de produ√ß√£o ‚Üí](./PRODUCTION_SETUP.md)**

---

### **Modo 3: Desenvolvimento (DeepSeek - barato)**

Para desenvolvimento ou testes com LLM.

```bash
# .env.local
DEEPSEEK_API_KEY=sk-...sua-chave-aqui...
```

**Nota:** DeepSeek requer cr√©ditos (~$5-10). Se voc√™ viu o erro "Insufficient Balance", precisa adicionar cr√©ditos em https://platform.deepseek.com

---

### **Modo 4: Local (Ollama - gr√°tis, avan√ßado)**

Para rodar localmente sem API externa.

```bash
# 1. Instale Ollama
brew install ollama  # macOS

# 2. Baixe um modelo
ollama pull llama3.1:8b

# 3. Rode o servidor
ollama serve

# 4. Configure
# .env.local
OLLAMA_BASE_URL=http://localhost:11434
```

---

## üîç Status do LLM

Verifique qual provider est√° ativo:

```bash
curl http://localhost:3000/api/health/llm
```

**Resposta:**
```json
{
  "llm": {
    "active": "openai",  // ou "deepseek", "ollama", null
    "status": "enabled",  // ou "regex-only"
    "mode": "LLM Fallback (OpenAI GPT-4o-mini)"
  },
  "capabilities": {
    "regex": true,
    "llmFallback": true,
    "institutionalValidation": true,
    "multiAgencySupport": true
  }
}
```

---

## üìä Compara√ß√£o de Op√ß√µes

| Provider | Custo/m√™s* | Qualidade | Velocidade | Setup | Produ√ß√£o |
|----------|------------|-----------|------------|-------|----------|
| **Regex-only** | $0 | 70% | ‚ö°Ô∏è Muito r√°pido | Nenhum | ‚úÖ Sim |
| **DeepSeek** | ~$1-2 | 85% | üöÄ R√°pido | F√°cil | ‚ö†Ô∏è Teste |
| **OpenAI** | ~$10-15 | 95% | üöÄ R√°pido | F√°cil | ‚úÖ‚úÖ‚úÖ **Recomendado** |
| **Ollama** | $0 | 80-90% | üêå Lento | M√©dio | ‚ö†Ô∏è Apenas privado |

*Para 1000 queries/dia (70% regex, 30% scraping, 10% LLM usado)

---

## üöÄ Como o Sistema Funciona

```mermaid
graph TD
    A[Query: "Microsoft"] --> B{No banco de dados?}
    B -->|Sim| C[Retorna dados do DB]
    B -->|N√£o| D[Scrape ag√™ncias]
    D --> E{Regex encontrou?}
    E -->|Sim| F[Retorna rating]
    E -->|N√£o| G{LLM configurado?}
    G -->|Sim| H[LLM extrai rating]
    G -->|N√£o| I[Retorna "n√£o encontrado"]
    H --> F
    C --> J[Valida√ß√£o Institucional]
    F --> J
    J --> K[Resposta com checksums + audit trail]
```

**Em resumo:**
1. **Banco de dados** (gr√°tis, instant√¢neo)
2. **Regex** (gr√°tis, r√°pido, 70% dos casos)
3. **LLM** (opcional, pago, 10% dos casos quando configurado)

---

## üìñ Documenta√ß√£o Detalhada

- **[LLM_SETUP.md](./LLM_SETUP.md)** - Guia completo de configura√ß√£o de todos os providers
- **[PRODUCTION_SETUP.md](./PRODUCTION_SETUP.md)** - Setup para produ√ß√£o institucional com OpenAI
- **[INSTITUTIONAL.md](./INSTITUTIONAL.md)** - Documenta√ß√£o completa do sistema
- **[.env.example](./.env.example)** - Template de vari√°veis de ambiente

---

## ‚öôÔ∏è Vari√°veis de Ambiente

```bash
# ===================================
# Escolha UMA das op√ß√µes abaixo:
# ===================================

# Op√ß√£o 1: Regex-only (gr√°tis)
LLM_PROVIDER=none

# Op√ß√£o 2: OpenAI (produ√ß√£o)
OPENAI_API_KEY=sk-proj-...
LLM_PROVIDER=openai

# Op√ß√£o 3: DeepSeek (desenvolvimento)
DEEPSEEK_API_KEY=sk-...

# Op√ß√£o 4: Ollama (local)
OLLAMA_BASE_URL=http://localhost:11434
```

---

## üß™ Testar Configura√ß√£o

```bash
# 1. Health check geral
curl http://localhost:3000/api/health

# 2. Health check do LLM
curl http://localhost:3000/api/health/llm

# 3. Teste com empresa no banco (regex, gr√°tis):
curl "http://localhost:3000/api/ratings-v2?q=Microsoft"

# 4. Teste com empresa n√£o no banco (LLM ser√° usado se configurado):
curl "http://localhost:3000/api/ratings-v2?q=Nubank"
```

**Veja os logs no terminal:**
```bash
[sp] ‚úÖ Manual extraction successful: AAA  # ‚Üê Regex funcionou (gr√°tis)
[sp] üöÄ Using LLM provider: OpenAI GPT-4o-mini  # ‚Üê LLM usado
[sp] ‚ö†Ô∏è No LLM provider configured  # ‚Üê Modo regex-only
```

---

## üêõ Problemas Comuns

### **"Insufficient Balance" (DeepSeek)**
- **Causa:** Conta sem cr√©ditos
- **Solu√ß√£o:** Adicione $5-10 em https://platform.deepseek.com
- **Ou:** Use OpenAI (mais confi√°vel) ou regex-only (gr√°tis)

### **"Invalid API Key"**
- **Causa:** Key incorreta ou expirada
- **Solu√ß√£o:** Regenere no dashboard do provider
- **Formato OpenAI:** `sk-proj-...` (come√ßa com `sk-proj-`)
- **Formato DeepSeek:** `sk-...`

### **Sistema n√£o usa LLM mesmo configurado**
- **Causa:** Regex est√° funcionando (isso √© BOM!)
- **Explica√ß√£o:** LLM s√≥ √© usado quando regex falha
- **Teste:** Use empresa n√£o no banco: `curl "...?q=Nubank"`

### **LLM muito lento**
- **Causa:** Usando Ollama em CPU lenta
- **Solu√ß√£o:** Use OpenAI ou DeepSeek (APIs cloud)

---

## üí∞ Estimativa de Custos Real

**Cen√°rio: 1000 queries/dia**

**Breakdown:**
- 700 queries ‚Üí Banco de dados = **$0** (cache hit)
- 200 queries ‚Üí Scraping com regex = **$0** (extra√ß√£o bem-sucedida)
- 100 queries ‚Üí Scraping sem regex = LLM usado

**Custo por query LLM:**
- OpenAI GPT-4o-mini: ~$0.0004/query
- DeepSeek: ~$0.0001/query

**Custo mensal:**
- 100 LLM queries/dia √ó 30 dias = 3000 queries/m√™s
- OpenAI: 3000 √ó $0.0004 = **$1.20/m√™s** ‚Üí **$14.40/ano**
- DeepSeek: 3000 √ó $0.0001 = **$0.30/m√™s** ‚Üí **$3.60/ano**

**Conclus√£o:** Custo desprez√≠vel para produ√ß√£o institucional.

---

## üèÜ Recomenda√ß√µes por Caso de Uso

### **Startup / MVP / Testes**
‚Üí **Regex-only** (gr√°tis)
- Configure: `LLM_PROVIDER=none`
- Funciona bem para 70% dos casos

### **Desenvolvimento / Staging**
‚Üí **DeepSeek** ($5-10 inicial)
- Configure: `DEEPSEEK_API_KEY=sk-...`
- Barato para testes com LLM

### **Produ√ß√£o Institucional**
‚Üí **OpenAI GPT-4o-mini** ($50 inicial)
- Configure: `OPENAI_API_KEY=sk-proj-...`
- Melhor qualidade, uptime 99.9%
- Suporte empresarial dispon√≠vel

### **Ambiente Privado / Offline**
‚Üí **Ollama** (gr√°tis, requer GPU)
- Configure: `OLLAMA_BASE_URL=http://localhost:11434`
- 100% privado, sem dados saindo da rede

---

## üéØ Pr√≥ximos Passos

1. **Escolha seu modo** (recomendamos come√ßar com regex-only)
2. **Configure `.env.local`** seguindo um dos exemplos acima
3. **Reinicie o servidor:** `npm run dev`
4. **Teste:** `curl http://localhost:3000/api/health/llm`
5. **Monitore os logs** para ver qual m√©todo est√° sendo usado

---

## üìû Suporte e Links

**Sistema:**
- Health: `GET /api/health`
- LLM Status: `GET /api/health/llm`
- Logs: JSON estruturado (stdout)

**Providers:**
- OpenAI: https://platform.openai.com/docs
- DeepSeek: https://platform.deepseek.com
- Ollama: https://ollama.ai

**Documenta√ß√£o:**
- [Guia de Setup](./LLM_SETUP.md)
- [Produ√ß√£o Institucional](./PRODUCTION_SETUP.md)
- [Sistema Completo](./INSTITUTIONAL.md)

---

**Feito com ‚ù§Ô∏è para an√°lise institucional de cr√©dito**

Sistema robusto com valida√ß√£o ISO-compliant, SHA-256 checksums, audit trails completos, e suporte multi-provider LLM.
