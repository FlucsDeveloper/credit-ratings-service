# LLM Configuration Guide

## Vis√£o Geral

O sistema de extra√ß√£o de ratings funciona em **2 camadas**:

1. **Regex (Sempre ativo)** - R√°pido, gr√°tis, determin√≠stico
2. **LLM Fallback (Opcional)** - Usado apenas quando regex falha

---

## üÜì Op√ß√£o 1: REGEX-ONLY (Recomendado para come√ßar)

**100% Gratuito | Sem API calls | R√°pido**

### Como configurar:

No seu `.env.local`, **N√ÉO adicione nenhuma chave de API**:

```bash
# Deixe vazio ou n√£o adicione essas linhas:
# OPENAI_API_KEY=
# DEEPSEEK_API_KEY=
# OLLAMA_BASE_URL=

# Ou force modo regex-only:
LLM_PROVIDER=none
```

### O que funciona:
- ‚úÖ Empresas no banco de dados (Microsoft, Apple, etc.) - **Instant√¢neo**
- ‚úÖ P√°ginas bem formatadas das ag√™ncias - **Regex consegue extrair**
- ‚úÖ 100% gratuito, sem limites
- ‚ùå P√°ginas mal formatadas ou artigos de not√≠cias - **Regex pode falhar**

---

## üí∞ Op√ß√£o 2: DeepSeek-V2 (Barato, mas pago)

**~$0.14/1M tokens | Requer cr√©ditos**

### Status atual:
Voc√™ tem o erro: `Insufficient Balance` (status 402) porque sua conta DeepSeek **n√£o tem cr√©ditos**.

### Como configurar:

1. Acesse: https://platform.deepseek.com
2. Adicione cr√©ditos (ex: $5-10)
3. Copie sua API key

No `.env.local`:
```bash
DEEPSEEK_API_KEY=sk-...sua-chave-aqui...
```

### Custo estimado:
- **Regex funciona**: $0 (maioria dos casos)
- **LLM usado**: ~$0.14/1M tokens
- **1000 extra√ß√µes com LLM**: ~$0.10-0.20

---

## üî• Op√ß√£o 3: OpenAI GPT-4o-mini (Melhor qualidade)

**~$0.15/1M tokens | Melhor para produ√ß√£o**

### Como configurar:

1. Acesse: https://platform.openai.com/api-keys
2. Crie uma API key
3. Adicione cr√©ditos ($5-10)

No `.env.local`:
```bash
OPENAI_API_KEY=sk-proj-...sua-chave-aqui...
```

### Prioridade:
OpenAI tem **prioridade** sobre DeepSeek. Se voc√™ configurar ambos, o sistema usa OpenAI.

### Custo estimado:
- **1000 extra√ß√µes com LLM**: ~$0.50-1.00

---

## üñ•Ô∏è Op√ß√£o 4: Ollama (Local, gr√°tis)

**$0 | Roda localmente | Requer GPU/CPU forte**

### Como configurar:

1. Instale Ollama: https://ollama.ai
2. Baixe um modelo:
   ```bash
   ollama pull llama3.1:8b
   # Ou outros: mistral, command-r-plus, deepseek-v2.5
   ```
3. Rode o servidor:
   ```bash
   ollama serve
   ```

No `.env.local`:
```bash
OLLAMA_BASE_URL=http://localhost:11434
```

### Ajustar modelo (opcional):

Edite `lib/ai/rating-extractor.ts` linha 46:
```typescript
model: 'llama3.1:8b', // Ou 'mistral', 'command-r-plus', etc.
```

### Requisitos:
- **8GB+ RAM** (para modelos 7-8B)
- **16GB+ RAM** (para modelos 13B+)
- GPU NVIDIA recomendada (mas funciona em CPU)

---

## üìä Compara√ß√£o de Op√ß√µes

| Op√ß√£o | Custo | Qualidade | Velocidade | Setup |
|-------|-------|-----------|------------|-------|
| **Regex-only** | $0 | 70% | ‚ö°Ô∏è Muito r√°pido | Nenhum |
| **DeepSeek** | $0.10-0.20/1k | 85% | üöÄ R√°pido | F√°cil |
| **OpenAI** | $0.50-1.00/1k | 95% | üöÄ R√°pido | F√°cil |
| **Ollama** | $0 | 80-90% | üêå Lento (CPU) | M√©dio |

---

## üîç Como o sistema escolhe o provider:

1. Se `LLM_PROVIDER=none` ‚Üí **Regex-only**
2. Se `OPENAI_API_KEY` existe ‚Üí **OpenAI**
3. Se `DEEPSEEK_API_KEY` existe ‚Üí **DeepSeek**
4. Se `OLLAMA_BASE_URL` existe ‚Üí **Ollama**
5. Caso contr√°rio ‚Üí **Regex-only**

---

## üß™ Testar sua configura√ß√£o:

```bash
# Teste uma empresa no banco de dados (regex apenas):
curl "http://localhost:3000/api/ratings-v2?q=Microsoft"

# Teste uma empresa N√ÉO no banco (vai tentar LLM se configurado):
curl "http://localhost:3000/api/ratings-v2?q=Raizen"
```

Veja os logs no terminal para saber qual m√©todo foi usado:
```
[sp] ‚úÖ Manual extraction successful: AAA  # ‚Üê Regex funcionou
[sp] ü§ñ LLM extraction result: {...}       # ‚Üê LLM foi usado
[sp] ‚ö†Ô∏è No LLM provider configured         # ‚Üê Regex-only mode
```

---

## ‚ùì Qual op√ß√£o escolher?

### Para testes e desenvolvimento:
‚Üí **Regex-only** (gr√°tis, j√° funciona bem)

### Para produ√ß√£o (baixo custo):
‚Üí **DeepSeek** (adicione $5-10 de cr√©ditos)

### Para produ√ß√£o (m√°xima qualidade):
‚Üí **OpenAI GPT-4o-mini** (melhor extra√ß√£o)

### Para rodar offline/privado:
‚Üí **Ollama** (100% local, sem API)

---

## üêõ Troubleshooting

### Erro: "Insufficient Balance" (DeepSeek)
- **Causa**: Conta DeepSeek sem cr√©ditos
- **Solu√ß√£o**: Adicione cr√©ditos em https://platform.deepseek.com

### Erro: "Invalid API Key" (OpenAI/DeepSeek)
- **Causa**: API key incorreta ou expirada
- **Solu√ß√£o**: Regenere a key no dashboard do provider

### LLM muito lento
- **Causa**: Usando Ollama em CPU lenta
- **Solu√ß√£o**: Use DeepSeek ou OpenAI, ou mude para modelo menor

### Sistema n√£o usa LLM mesmo com API key configurada
- **Causa**: Regex est√° funcionando (isso √© bom!)
- **Solu√ß√£o**: LLM s√≥ √© usado quando regex falha

---

## üìù Arquivo .env.local exemplo completo:

```bash
# ===================================
# ESCOLHA UMA OP√á√ÉO:
# ===================================

# Op√ß√£o 1: Regex-only (gr√°tis)
LLM_PROVIDER=none

# Op√ß√£o 2: DeepSeek (barato, requer cr√©ditos)
# DEEPSEEK_API_KEY=sk-...

# Op√ß√£o 3: OpenAI (melhor qualidade)
# OPENAI_API_KEY=sk-proj-...

# Op√ß√£o 4: Ollama (local, gr√°tis)
# OLLAMA_BASE_URL=http://localhost:11434

# ===================================
# Configura√ß√µes adicionais
# ===================================
NODE_ENV=development
```

---

## üöÄ Pr√≥ximos passos

1. Escolha uma op√ß√£o acima
2. Configure o `.env.local`
3. Reinicie o servidor: `npm run dev`
4. Teste com: `curl "http://localhost:3000/api/ratings-v2?q=Microsoft"`
5. Verifique os logs no terminal

**Recomenda√ß√£o inicial**: Comece com **Regex-only** (gr√°tis). Se precisar de mais cobertura, adicione DeepSeek ($5-10).
